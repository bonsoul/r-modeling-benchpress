---
title: "xgboost for childcare costs"
author: "Bonsoul"
date: "`r Sys.Date()`"
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set( cache = TRUE, cache.lazy = FALSE, warning = FALSE, message = FALSE ,  echo = TRUE , dpi = 180, fig.width = 8, fig.height = 5)
```

```{r, set up}

library(tidytuesdayR)
library(silgelib)
library(ggplot2)
theme_set(theme_plex())
update_geom_defaults("rect", list(fill = "midnightblue", alpha = 0.8))
update_geom_defaults("line", list(color = "midnightblue", alpha = 0.8))


```

```{r}

library(tidyverse)

tuesdata <- tidytuesdayR::tt_load('2023-05-09')
tuesdata <- tidytuesdayR::tt_load(2023, week = 19)

childcare_costs <- tuesdata$childcare_costs
counties <- tuesdata$counties

```




```{r}
childcare_costs |>
  ggplot(aes(study_year ,mcsa, group = study_year, fill = study_year)) +
  geom_boxplot(alpha = 0.8, show.legend = FALSE) +
  scale_fill_distiller(palette = "RdPu")


```

```{r}

childcare_costs |>
  ggplot(aes(mhi_2018, mcsa, color = flfpr_20to64)) +
  geom_point( alpha = 0.5) +
  scale_x_log10() +
  scale_color_viridis_c()
  
```


```{r, race}

childcare_costs |> 
  select(mcsa, mhi_2018, starts_with("one_race")) |>
  select(-one_race) |>
  pivot_longer(starts_with("one_race")) |>
  ggplot(aes(value, mcsa, color = mhi_2018)) +
  geom_point(alpha = 0.4) +
  facet_wrap(vars(name), scales = "free_x") +
  scale_color_viridis_c()

```

##model

```{r}

library(tidymodels)

childcare_split <- 
  childcare_costs |>
  select(-matches("^mc_|^mf")) |>
  select(-county_fips_code) |>
  na.omit() |>
  initial_split(strata  =mcsa)

childcare_train <- training(childcare_split)
childcare_test <- testing(childcare_split)

set.seed(234)
childcare_set <- validation_split(childcare_train)
childcare_set

```

```{r}
library(recipes)

xgb_rec <- recipe(mcsa ~ ., data = childcare_train)

```


```{r}
prep(xgb_rec, training = childcare_train) %>%
  juice()

```


```{r}
library(parsnip)

xgb_spec <- boost_tree(
  trees = tune(),
  tree_depth  = tune(),
  learn_rate = tune(),
  loss_reduction = tune(),
  sample_size = tune(),
  mtry = tune()
) %>%
  set_engine("xgboost") %>%
  set_mode("regression")

```


```{r}
library(workflows)

xgb_wf <- workflow() %>% 
  add_recipe(xgb_rec) %>%
  add_model(xgb_spec)

```

```{r, metrics}
library(yardstick)

metrics <- metric_set(rmse,rsq)

```

```{r}

params <- parameters(xgb_spec) %>%
  finalize(childcare_train)

xgb_rs <- tune_grid(
  xgb_wf,
  resamples = validation_split(childcare_train, prop = 0.75),
  metrics = metrics,
  grid = grid_latin_hypercube(params, size = 20)
)


```

